
"""
    Name: Xiuyi Feng
    Email: xiuyi.feng15@myhunter.cuny.edu
    Resources:
            https://stackoverflow.com/questions/43757977/replacing-values-greater-than-a-number-in-pandas-dataframe
            https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html
"""
import pickle
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix


def clean_reg(reg):
    """
        If reg is coded as passenger 'PAS' or commercial 'COM',
        return those values. Otherwise, return 'OTHER'.
    """
    if reg=='PAS':
        return 'PAS'
    if reg =='COM':
        return 'COM'
    return 'OTHER'

def clean_color(col):
    """
        return corresponding color base on the input parameter col
    """
    if col in {'GY', 'GRAY', 'GREY', 'SILVE', 'SIL', 'SL'}:
        return 'GRAY'
    if col in {'WH', 'WHITE'}:
        return 'WHITE'
    if col in {'BK', 'BLACK', 'BL'}:
        return 'BLACK'
    if col == 'BLUE':
        return 'BLUE'
    if col in {'RED', 'RD'}:
        return 'RED'
    if col in {'GR', 'GREEN'}:
        return 'GREEN'
    if col in {'BROWN', 'TAN'}:
        return 'BROWN'
    return 'OTHER'


def add_indicators(dff,cols=['Registration', 'Color', 'State']):
    """
        Returns the DataFrame with an additional indicator columns generated by
        get_dummies for specified columns. The drop_first flag is set to True to
        drop extraneous columns.
    """
    new_dff = pd.get_dummies(dff[cols], drop_first = True)
    return new_dff


def add_excessive_flag(dff, threshold=5):
    """
        Returns the DataFrame with a new column, Excessive Tickets which is 0
        if there's less threshold number of Tickets and 1 otherwise.
    """
    dff["Excessive Tickets"].values[dff['Tickets'] >= threshold] =1
    dff["Excessive Tickets"].values[dff['Tickets'] < threshold] =0
    return dff

def split_data(dff, x_cols, y_col, test_size = 0.25, random_state = 2023):
    """
        Returns the data split into 4 subsets, corresponding to those returned by
        train_test_split: x_train, x_test, y_train, and y_test. where units is the
        "x" column and the input parameter, y_col_name is the "y" column.
    """
    xes = dff[x_cols]
    yes = dff[y_col]
    x_train, x_test, y_train, y_test = train_test_split(xes, yes,
    test_size=test_size, random_state=random_state)
    return x_train, x_test, y_train, y_test


def fit_model(x_train, y_train, model_type='logreg'):
    """
        The resulting model should be returned as bytestream, using pickle base on the model_type
    """
    if model_type == "logreg":
        model = LogisticRegression(solver='saga', penalty='l2', max_iter=5000)
    elif model_type == 'nbayes':
        model = GaussianNB()
    elif model_type == "svm":
        model = SVC(kernel='rbf')
    elif model_type == 'rforest':
        model = RandomForestClassifier(n_estimators=100, random_state=0)
    model.fit(x_train, y_train)
    mod_pkl = pickle.dumps(model)
    return mod_pkl

def score_model(mod_pkl,xes,yes):
    """
        Returns the confusion matrix for the model.
    """
    model = pickle.loads(mod_pkl)
    y_pred= model.predict(xes)
    conf_matrix = confusion_matrix(yes, y_pred)
    return conf_matrix

def compare_models(x_test, y_test, models):
    """
        For each of the specified models in models, calls score() function of each
        model on x_test and y_test. The function returns the index of the model with
        highest accuracy score and its accuracy score (i.e. 0 if it is the first model
        in the list, 1 if it is the second model in the list, etc). In case of ties for
        the best score, return the first one that has that value.
    """
    highest_accuracy_score_index=0
    highest_accuracy_score=0.0
    for index, model_type in enumerate(models):
        model = pickle.loads(model_type)
        score = model.score(x_test, y_test)
        if score > highest_accuracy_score_index:
            highest_accuracy_score_index = index
            highest_accuracy_score = score
    return highest_accuracy_score_index - 1, highest_accuracy_score
